{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading one of the models I trained previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'fix.loss.300.noclip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import LSTMLanguageModel, load_losses, plot_losses\n",
    "from generate import print_pred, generate_sentences\n",
    "import json\n",
    "import torch\n",
    "import data, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMLanguageModel.load(f'output/{MODEL_NAME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = load_losses(f'output/{MODEL_NAME}_losses.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's feed a sentence into this model that ends in an end-of-sentence symbol. What probability does it give for the start-of-sentence symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [data.START_OF_VERSE_TOKEN] + 'this is some test sentence'.split() + [data.END_OF_VERSE_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence_ids = [model.word_index[word] for word in test_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_ids = [test_sentence_ids]\n",
    "test_batch_tensor = torch.tensor(test_batch_ids)\n",
    "test_batch_lens = torch.tensor([len(test_sentence_ids)])\n",
    "word_scores = model(test_batch_tensor, test_batch_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_word_scores = word_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_scores = sent_word_scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_probs = torch.nn.functional.softmax(next_word_scores, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = train.invert_dict(model.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_prob = {index_word[i]: prob.item() for i, prob in enumerate(next_word_probs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_prob['and'], next_word_prob[data.START_OF_VERSE_TOKEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what I expected. I expected that P(SOS|EOS) = 1, but I'm getting much higher probabilities for other words than for SOS.\n",
    "\n",
    "Another question is: if I feed w1w2w3, is P(w2) in slot 1 the same as if I feed w1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_sentence = [data.START_OF_VERSE_TOKEN, 'this']\n",
    "long_sentence = f'{data.START_OF_VERSE_TOKEN} this is a sentence {data.END_OF_VERSE_TOKEN}'.split()\n",
    "short_seq, long_seq = [torch.tensor([[model.word_index[word] for word in sent]]) \\\n",
    "                       for sent in (short_sentence, long_sentence)]\n",
    "short_seq_len, long_seq_len = [torch.tensor([len(sent)]) for sent in (short_sentence, long_sentence)]\n",
    "short_pred = model(short_seq, short_seq_len)\n",
    "long_pred = model(long_seq, long_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all([(abs(short_pred[0][1][i] - long_pred[0][1][i]) / short_pred[0][1][i]).item() < 0.0001 \\\n",
    "     for i in range(len(short_pred[0][1]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(short_pred[0][1]) == len(long_pred[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, it seems that as long as the previous sequences are equal, the probabilities are equal. This means that we can feed a long sequence once, and get the probabilities for each slot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the perplexity of a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.perplexity_loss_function = torch.nn.CrossEntropyLoss(\n",
    "            ignore_index=model.word_index[data.PAD_TOKEN],\n",
    "            reduction='sum'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_perplexity([f'this is a sentence'.split()], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we want to do is to compute the perplexity for every epoch on the validation dataset. This will allow us to monitor how it evolves with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word_order_bibles",
   "language": "python",
   "name": "word_order_bibles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
